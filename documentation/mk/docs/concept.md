## Concept

Fragment provides a uniquely approach to sound synthesis and composition with the capability to generate audio and visuals in real-time and at the same time.

A vast range of sound and music can be created with fine control over harmonic content and spatial dynamics. 

### Visuals

Fragment canvas is the source of the visuals and also the source of the sound synthesis.

Visuals are generated by the user by giving instructions to the GPU with a simple high-level programming language called GLSL, the Fragment GLSL script (also called a fragment shader) is called by the GPU for every pixels on the canvas. This approach allow very fast real-time manipulation of the pixels data.

Fragment has only one fragment shader which has the particularity to be shared between the users of an online session, it update and compile on-the-fly as you or other peoples type, this is the collaborative nature of Fragment, visuals and sounds can be produced online.

Some Fragment settings are also synchronized between users such as slices, some global settings and uniforms.

### Sound Synthesis

Fragment is an image-synth, the sound synthesis source of data is the **pixels** also called a **fragment**.

With Fragment, all sounds is operated from a frequency level, amplitudes are assigned to frequencies to produce sounds, this is valid for all synthesis techniques.

Since the sound synthesis source of data is the pixels, we need a way to capture them, this is done by slicing the canvas, pixels data (1px wide) are then captured from the slice at the browser display refresh rate and are then translated to notes from the RGBA pixels value, the notes are then interpreted and played by one or more synthesis method in real-time.

The canvas represent frequencies (exponential map) on the vertical axis, the horizontal axis generally represent time.

There is many type of sound synthesis available within Fragment, all work from the same concept, **the pixels**.

#### Additive Synthesis

> **Additive synthesis** is a sound synthesis technique that creates [timbre](https://en.wikipedia.org/wiki/Timbre) by adding [sine](https://en.wikipedia.org/wiki/Sine) waves together.

Fragment default sound synthesis is additive, with additive synthesis, Fragment become a fully capable spectral synthesizer able to do re-synthesis based on imported images, videos or audio files, an image-synth where any number of partials can be generated, there is no limits except the canvas height and the computing resources available.

#### Granular Synthesis

> **Granular synthesis** is a sound synthesis technique that operates on the microsound time scale, it is based on the same principle as [sampling](https://en.wikipedia.org/wiki/Sampling_(music)).

Fragment secondary sound synthesis is granular, the grains source are based on audio samples, this method is only available with the audio server and provide asynchronous and synchronous granular synthesis.

Just like additive synthesis, re-synthesis can be done with granular synthesis and most granular parameters can be manipulated by the user.

The combination of granular synthesis and additive synthesis provide powerful sound capabilities which can sound quite organic.

#### Sampler

Fragment can also act like a regular sampler, this method is only available with the audio server, it is a work in progress and may work partially.