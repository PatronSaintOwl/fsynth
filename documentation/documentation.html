<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<style>
p                                 {  width: 600px; }
.dropdown                         { position: relative;
                                    display: inline-block; }
.drp-content                      { display: none; 
                                    position: fixed;
                                    bottom: 10px; 
                                    right: 10px; 
                                    background-color: #ffcc00;
                                    max-width: 500px; 
                                    box-shadow: 0px 16px 16px 0px rgba(0,0,0,0.6);
                                    padding: 0px 6px; 
                                    z-index: 0; }
.dropdown:hover      .drp-content { display: block; 
                                    z-index: 2; }              
</style>
</head><body><center><table style="width: 600px; font-size:12px;"><tr><td><div style=" text-justify: inter-word; width: 600px; line-height: 17px; ">



















      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      


















<div style="text-align: center; color: inherit; font-size: inherit;"><p><span style="font-size: 120%;"><span style="font-size: 120%;"><span style="font-size: 120%;"><span style="font-size: 120%;"><span style="font-size: 120%;">Fragment</span></span></span></span></span></p></div>
<div style="text-align: center; color: inherit; font-size: inherit;"><p><span style="font-size: 120%;"><span style="font-size: 120%;">The Collaborative Spectral Synthesizer</span></span></p></div>
<div style="text-align: center; color: inherit; font-size: inherit;"><p>by Julien Verneuil - contact@fsynth.com</p></div>
<br>
<div style="text-align: center; color: inherit; font-size: inherit;"><p><span style="font-size: 120%;">This is the HTML documentation of the Fragment synthesizer.</span></p></div>
<div style="text-align: center; color: inherit; font-size: inherit;"><p>The PDF documentation can be found <a href="https://www.fsynth.com/pdf/fragment_documentation.pdf">here</a></p></div>
<div style="text-align: center; color: inherit; font-size: inherit;"><p><a href="https://www.fsynth.com"><img src="images/fsynth_ui.png" width="580"></a></p></div>
<br>
<div style="text-align: center; color: inherit; font-size: inherit;"><p><strong>Table of Contents</strong></p></div>
<a rel="tag" href="#sec1"><br><strong>1. Introduction</strong><br></a><a rel="tag" href="#subsec1_1"><div align="left" style="display: inline-block; width: 20px;"></div>1.1. History<br></a><a rel="tag" href="#subsec1_2"><div align="left" style="display: inline-block; width: 20px;"></div>1.2. Capabilities<br></a><a rel="tag" href="#subsec1_3"><div align="left" style="display: inline-block; width: 20px;"></div>1.3. System requirements<br></a><a rel="tag" href="#subsubsec1_3_1"><div align="left" style="display: inline-block; width: 40px;"></div>1.3.1.Browser<br></a><a rel="tag" href="#subsubsec1_3_2"><div align="left" style="display: inline-block; width: 40px;"></div>1.3.2.CPU<br></a><a rel="tag" href="#subsubsec1_3_3"><div align="left" style="display: inline-block; width: 40px;"></div>1.3.3.GPU<br></a><a rel="tag" href="#sec2"><br><strong>2. Concepts</strong><br></a><a rel="tag" href="#subsec2_1"><div align="left" style="display: inline-block; width: 20px;"></div>2.1. Additive synthesis<br></a><a rel="tag" href="#subsec2_2"><div align="left" style="display: inline-block; width: 20px;"></div>2.2. The graphical score<br></a><a rel="tag" href="#sec3"><br><strong>3. Sessions</strong><br></a>
<a id="sec1"></a><br><br><span style="font-size: 120%;"><span style="font-size: 120%;"><strong>1. Introduction</strong></span></span><br><br>
The <strong><a href="https://www.fsynth.com">Fragment synthesizer</a></strong> (also called fsynth) is a collaborative web-based musical instrument which allow direct manipulation of the sound spectrum by the use of on-the-fly GPU (Graphics Processing Unit) programming.<br><br>Fragment is stereophonic, polyphonic, multitimbral and support live coding of audio and visuals at the same time.<br><br>Fragment is first and foremost a powerfull additive synthesizer which let you have complete control over the sound spectrum in real-time with direct visual feedback.<br><br>Many videos of Fragment live sessions were recorded and are available on YouTube as a <a href="https://www.youtube.com/playlist?list=PLYhyS2OKJmqe_PEimydWZN1KbvCzkjgeI">playlist</a>.<br><br><br>
<a id="subsec1_1"></a><span style="font-size: 120%;"><strong>1.1. History</strong></span><br><br>
In 2009, i discovered the <a href="http://www.warmplace.ru/soft/ans/">Virtual ANS</a> synthesizer by <a href="http://www.warmplace.ru">Alexander Zolotov</a>,
a software emulation of the Russian photoelectronic synthesizer <a href="http://en.wikipedia.org/wiki/ANS_synthesizer">ANS</a> which was created by the Russian engineer <a href="http://en.wikipedia.org/wiki/Evgeny_Murzin">Evgeny Murzin</a> from 1938 to 1958.<br><br>I was blown away by the remarquable possibilities offered by the Virtual ANS which let you draw the sound spectrum over time, i then discovered programs such as MetaSynth or <a href="https://highc.org">HighC</a>, this is how i started to experiment with the "drawn sound" method.<br><br>Fragment started in 2015, when i was making the first prototype of a web-based ANS-like synthesizer software which is still a work in progress, a prototype of Fragment was made in a single week, 
the prototype was quite mature but lacked in features, i considered Fragment as a pretty but failed experiment at the time.<br><br>In the summer 2016 while i was releasing the prototype source code, i played with it again and after tweaking the GLSL code, i was able to make some nice sounds and envision what would be possible with this technology, so i started to think about that prototype again and come up with many ideas that would make Fragment more functional and easier to use, the real work begun.<br><br>After many hours spent crafting the software, the first version of Fragment was released in January 2017, it was quite limited at that time, Fragment has now improved alot.<br><br><br>
<a id="subsec1_2"></a><span style="font-size: 120%;"><strong>1.2. Capabilities</strong></span><br><br>
<span><ul>
	<li> Powerful additive synthesizer
		<span><ul><li> Powered by WebAudio oscillators <li> Powered by <a rel="tag" href="#fas">FAS</a>, an independent program <li> Powered by a wavetable </ul></span>
	<li> Stereophonic
	<li> Monaural
	<li> Polyphonic
		<span><ul><li> Automatically detected from the GPU capabilities <li> 16 notes minimum <li> 704 notes with a GeForce GTX 970 GPU</ul></span>
	<li> Multitimbral
	<li> Spectral recording with mixing and export as PNG
	<li> Adjustable audio output channel per slices
		<span><ul><li> Multiple audio channels are only supported with <a rel="tag" href="#fas">FAS</a></ul></span>
	<li> Shader inputs, webcam, textures, audio files
	<li> MIDI Enabled
		<span><ul><li> Only with WebMIDI API enabled browsers (Google Chrome) <li> Hot plugging of MIDI devices is supported</ul></span>
	<li> Collaborative app.
		<span><ul><li> MIDI and shader inputs are not synchronized between users</ul></span>
  <li> Feedback support
	<li> Live coding/JIT compilation of shader code
	<li> Global and per sessions settings automatic saving/loading
	<li> No authentifications (sessions based)
	<li> Per-sessions discussion system</ul></span>
<br>
<a id="subsec1_3"></a><span style="font-size: 120%;"><strong>1.3. System requirements</strong></span><br><br>
Fragment is a special kind of additive synthesizer which require a moderate deal of processing power in order to work properly, a medium-end GPU and CPU should work fine.
<br>
<a id="subsubsec1_3_1"></a><br><br><strong>1.3.1. Browser</strong><br><br>
Fragment require a browser with full support for ECMAScript 5, CSS3, WebAudio and WebGL.<br><br>Well-tested and compatible browsers include Firefox 51.x and Chrome 55.x but Fragment may work with previous version of those browsers as well.<br><br>It is known to work on recent version of Safari and Opera as well.<br><br>Chrome or Chromium browser is recommended.<br><br>Fragment support the WebGL 2 API which improve performances and enable some advanced features in the fragment shader due to GLSL 3.0 usage.
<br>
<a id="subsubsec1_3_2"></a><br><br><strong>1.3.2. CPU</strong><br><br>
Fragment may be quite hungry in term of computing resources, a dual core with high clock speed is recommended, a CPU with more cores can be useful if you just want to use the browser for audio output.<br><br>Several methods are provided to synthesize sounds, each with performances pros and cons:
<span><ul>
	<li> <a rel="tag" href="#fas">FAS</a> (<strong>recommended</strong>): <span><ul><li> Very fast <li> Multiple output support with soundcard choice <li> Many settings <li> Can run on a dedicated computer such as a Raspberry PI <li> Dedicated program which receive Fragment data over the network <li> Enhanced noise modeling by adding band-limited noise</ul></span>
	<li> WebAudio oscillators: <span><ul><li> Fastest under Chrome <li> May not work with Firefox <li> Require a fast CPU <li> Integrated global "release" envelope</ul></span>
	<li> Wavetable (not recommended): <span><ul><li> Most compatible browser method <li> Will produce crackles</ul></span></ul></span>
<a id="subsubsec1_3_3"></a><br><br><strong>1.3.3. GPU</strong><br><br>
Fragment was developed and tested with a NVIDIA GeForce GTX 970 GPU, a powerful GPU may be required if:
<span><ul>
	<li> you want higher score resolution
	<li> you want to do visuals alongside audio
	<li> you are doing complex things/use many inputs in your shader
	<li> you want greater polyphonic/harmonics/partials capabilities</ul></span>
<a id="sec2"></a><br><br><span style="font-size: 120%;"><span style="font-size: 120%;"><strong>2. Concepts</strong></span></span><br><br>
Fragment is an additive synthesizer, it let you have full control over the timbral qualities of your sounds by the mean of GPU programming.<br><br>Unlike other additive synthesizer software, there is no need for knobs, sliders or any other controllers to sculpt your sounds, all of that is done by generating visuals which will determine your sounds harmonic content and dynamic characteristics.<br><br>There is many features in Fragment which allow any creative minds to produce complex sounds in different ways and even with external tools, i suggest all the readers to look at great softwares like the <a href="https://www.iannix.org">IanniX sequencer</a> and to use it with Fragment using the MIDI capabilities.<br><br>While Fragment may seem overwhelming at first, the only thing that is required to produce sounds with it is to know how to generate the visuals.<br><br>The goal of this section is to clarify the inner working of Fragment.<br><br><br>
<a id="subsec2_1"></a><span style="font-size: 120%;"><strong>2.1. Additive synthesis</strong></span><br><br>
Fragment is first and foremost a powerful additive synthesizer which make an extended use of additive synthesis.<br><br>Additive synthesis is a sound synthesis technique that creates timbre by adding sine waves together.<br><br>Adding sine waves produce a timbre, the timbre quality is mainly defined by its harmonic content and the dynamic characteristics of the harmonic content.<br><br>The concept of additive synthesis is centuries old, it has first been used by pipe organs.<br><br>Fragment can theoretically produce any timbres with precise accuracy.<br><br>The only limit to the amount of sine waves that can be added by Fragment is the limit of the available processing power.<br><br>For example, on a Raspberry PI 3 (1.2GHz 64-bit quad-core ARMv8 CPU) ~700 oscillators can be played simultaneously using two cores, matching the capability of the ANS synthesizer.<br><br>Actually, there is a also a hard limit which is that the frequency capture of slices cannot go beyond the refresh rate of your monitor (and this also depend on the browser implementation), this could however be bypassed easily by switching to a different monitor.<br><br>Fragment can also do other types of synthesis like substractive synthesis.<br><br><br>
<a id="score"></a>
<a id="subsec2_2"></a><span style="font-size: 120%;"><strong>2.2. The graphical score</strong></span><br><br>
Fragment graphical score represent the sound spectrum which is generated by the GPU from a fragment program.<br><br>The fragment program (also known as a fragment shader) is executed by the GPU and compute the color and other attributes of each "fragment" - a technical term which usually mean a single pixel.<br><br>The graphical score represent a kind of sonic canvas where the X axis represent time and the Y axis represent frequencies, you "paint" the graphical score by writing a fragment program which will be executed for each pixels of the graphical score.<br><br>What you hear in Fragment is determined by the position of "slices" which are added on the graphical score, slices are vertical bits of the graphical score which are merged together and produce an audible result.<br><br>The content of slices is captured at the rate of display refresh rate which conventionally should be 60fps most of the time.<br><br>The frequency mapping of the graphical score is fixed by a logarithmic formula, altough the formula cannot be changed right now, some parameters are available in the settings dialog to fine tune the frequency map.<br><br>The frequency mapping is defined by the formula:
<p style="text-align: center;"><img src="png/fJCBv8mOl-C9YgjNVFHoP3ypseu8.png" width="106" height="25" style="vertical-align: -0px"></p>
Where:
<span><ul>
	<li> <strong>a</strong> is is the starting frequency
	<li> <strong>y</strong> the vertical position
	<li> <strong>n</strong> the number of oscillators (which is the height of the canvas)
	<li> <strong>o</strong> the octave count</ul></span>
	
<a id="sec3"></a><br><br><span style="font-size: 120%;"><span style="font-size: 120%;"><strong>3. Sessions</strong></span></span><br><br>
Fragment sessions are isolated spaces which are open to all peoples who has access to the session name, they can be joined by going to the Fragment <a href="https://www.fsynth.com">homepage</a> or by typing the session name directly into the address bar as demonstrated below.<br><br>You can join any sessions directly from your browser address bar by replacing "yoursessionname" for the URL shown below by the session name you want to join or create, session names are limited to a maximum of 100 characters and cannot have the "Lexical error in '/home/julien/Projets/fs/documentation/documentation at 180:249[11514]': $" at line 179</div></td></tr></table></center></body></html>